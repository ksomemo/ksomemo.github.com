# 集計／分析／機械学習の流れ
## 流れ
最近pandasやnumpy, sklearnに力入れてたので、それが必要な流れをなにも見ずに書いてみた

## 書いてみて思ったこと
- コンペのようなデータセットが用意されている場合と、自分たちのサービス改善のためだとだいぶ違う
- あとで分解したほうがよさそう

## 詳細
1. 目的決定
    2. なにを解決したいのか
        3. 定点観測のため(KGIからのKPI)
        4. 定点観測からの深掘りのための分析(今回の目的)
        5. レコメンドなどのシステムでも利用(今回の目的とは違う？)
2. データ用意
    3. 集計
        3. どんなデータか/もしくは必要か
            6. マスタ/トランザクション
            7. 差分/Dump
        4. データの提供タイミング
        5. 自動化してためこめるか
        7. どのデータと関連がある(結合できる)
        8. データ量はストレージに対して問題ないか
            9. 集約するかどうか
    10. 分析
        11. 変数の作成の計画
3. データ把握
    2. 尺度の把握(参考書たくさんある)
        3. 連続
            4. 0基準等の比例(よく使う
            5. 間隔(あんまり使ってない
        4. その他
            5. 順序/カテゴリ(二値含む
    4. 単変数
        5. 連続
            6. ヒストグラム(分布確認
            7. 箱ひげ図(外れ値ざっくり確認)
            7. 要約統計量(箱ひげ図で見れない平均をみる/四分位数/min,max,std)
            8. NAの数
        8. その他
            9. カテゴリ種類
            10. 種類別カウント
                11. 棒グラフ
            11. 上記の構成比率
                12. 100%積み上げ棒グラフなど
    5. ２変数
        6. 連続
            6. 散布図行列(重くなければ一気に見てしまう
            6. 相関係数/相関係数行列ヒートマップ
        7. その他
            8. カテゴリ×目的変数の箱ひげ図
        9. 目的変数がある場合
            10. 目的変数がカテゴリなら
                11. 連続とのカテゴリ別ヒストグラム(別々,積み上げ)
            12. 目的変数が連続なら
                12. カテゴリとのカテゴリ別箱ひげ図
    6. 多変数
        7. 散布図の目的カテゴリ別に色分け
        7. クロス集計
            8. 行/列それぞれの総数での集計
            9. 各セルの全体における構成比率
            8. 行/列単位の構成比率
            9. 行列のオッズ/オッズ比
            10. カイ二乗検定
        8. クロスグラフ
            9. 集計ではなくクロスしたセルにヒストグラムなど
2. 前処理
    3. 外れ値除外
    4. 欠損値除外or埋め
    6. ダミー変数(kカテゴリ -1個)
    5. 縦持ち横持ち変換(縦のUnique化 and 説明変数の分解/ダミー変数に似ている)
    6. 文字列変数の規則
        7. titanicの名前の例
    8. ドメイン知識からひねり出す
        9. 前処理につながる
    7. 離散化(segmentation ?)
        8. 連続量身長を大中小の順序に変換,解釈しやすくなることもある
        8. デシル分析など
    8. 日付の分解/集約
        9. 日時
            10. 時間帯別(0~23,AM/PM,朝昼晩夜)
            11. 年月日分解
        12. ある基準からの経過時間
            13. 初回利用日-会員登録日など(N日後利用)
            14. 集計最終日-直近の利用日(N日前利用)
                15. RFMのRecency
        15. 利用日のUniqueカウント(利用日数)
            16. 連続量以外でもRFMのFrequncyにする
    7. 正規化(標準化,MinMaxScale,etc.)
    8. 多重共線性/分散の少なすぎる説明変数の選定と削除
    8. その他データセットとの結合
        9. SQLでは複雑になる場合
        10. DBに格納されていないファイル,異なるDBのデータ
    9. 時系列系処理
        10. 移動平均,自己相関など(あんまり知らない
    8. などなど
    5. 再度データ把握
3. モデル選定
    4. ここ分布やドメインによっていろいろ変える
4. 学習
    5. 過学習/汎化能力のためのデータ準備
        8. Cross Validation
    6. 説明変数用
    7. ハイパーパラメータ用
5. 検証
    6. 係数の重要度
        7. 施策に活かせるかつコントロールできる変数を探す
        7. 回帰係数
        8. 決定木系
    6. いろんな評価指標
        7. 回帰
            8. RMSE
        9. 分類
            10. confusion matrixからのnegative/positive/True/Falseによる指標
6. 繰り返し

- この流れさえ見失わなければ、大枠ははずさないはず
- この流れに合うAPIを探す
    - 評価系が甘い
    - 教師なし評価についてまだわかっていない
    - NN系はわからない
    - 画像/テキスト系もわからない


## 分析のための考え方
- 目標設定
- volume と 割合
    - ex. 割合(効果)が高くても、volumeがなければ売上にならない
    - 構成比率
    - 正規化/標準化
- diff/推移
    - 時系列
- 今回集計したものと、前回集計したものを比較
    - これも定期的に等間隔で行いデータを増やせば、集計結果を時系列として比較できる

## 分析/機械学習のための知識
- math
    - 微分積分
    - 線形代数
    - 確率
    - 組合せ
    - 数学かわからないけど、いろいろな距離
- english
    - わからなかったらGoogle Translate
- programming
    - if,for,iteratorなどの基本
    - DataFrameと行列ライブラリ慣れ
